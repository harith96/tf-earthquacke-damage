{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorical columns\n",
    "\n",
    "#land_surface_condition\n",
    "#foundation_type\n",
    "#roof_type\n",
    "#ground_floor_type\n",
    "#other_floor_type\n",
    "#position\n",
    "#plan_configuration\n",
    "#legal_ownership_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Training Data\n",
    "X_train = pd.read_csv(\"train_values.csv\").drop(columns=['building_id'])\n",
    "Y_train = pd.read_csv(\"train_labels.csv\").drop(columns=['building_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding Categorical Columns\n",
    "categorical_cols = ['land_surface_condition','foundation_type','roof_type','ground_floor_type','other_floor_type','position','plan_configuration','legal_ownership_status'];\n",
    "\n",
    "for col in categorical_cols:\n",
    "    X_train[col] = pd.Categorical(X_train[col])\n",
    "    X_test[col] = pd.Categorical(X_test[col])\n",
    "    \n",
    "dummies = pd.get_dummies(X_train['land_surface_condition'], prefix = 'land_surface_condition')\n",
    "for i in range (1,len(categorical_cols)):\n",
    "    dummies = pd.concat([dummies, pd.get_dummies(X_train[categorical_cols[i]], prefix = categorical_cols[i])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "scaler = MinMaxScaler();\n",
    "\n",
    "X_train = X_train.drop(columns=categorical_cols)\n",
    "X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "concated = False\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add categorical columns after feature scaling\n",
    "if(not(concated)):\n",
    "    X_train = pd.concat([X_train, dummies],axis=1)\n",
    "    concated = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Data To Be Inserted Into Tensorflow Model\n",
    "X_training_test = X_train.sample(1024)\n",
    "Y_training_test = Y_train.sample(1024)\n",
    "\n",
    "Y_training_test-=1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((tf.cast(X_training_test.values, tf.float32),\n",
    "            tf.cast(Y_training_test.values, tf.int32)))\n",
    "dataset = dataset.shuffle(1000).repeat(10).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Declaration\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(keras.layers.Dense(68, activation=tf.nn.tanh, input_dim=68))\n",
    "model.add(keras.layers.Dense(128, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(3, activation=tf.nn.softmax))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, x, y):\n",
    "  y_ = model(x)\n",
    "  return tf.losses.sparse_softmax_cross_entropy(labels=y, logits=y_)\n",
    "\n",
    "def grad(model, inputs, targets):\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss_value = loss(model, inputs, targets)\n",
    "  return loss_value, tape.gradient(loss_value, model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.03)\n",
    "\n",
    "global_step = tf.Variable(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Note: Rerunning this cell uses the same model variables\n",
    "from tensorflow import contrib\n",
    "tfe = contrib.eager\n",
    "\n",
    "# keep results for plotting\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  epoch_loss_avg = tfe.metrics.Mean()\n",
    "  epoch_accuracy = tfe.metrics.Accuracy()\n",
    "\n",
    "  # Training loop - using batches of 32\n",
    "  for x, y in dataset:\n",
    "#     print(\"x : {}\".format(x))\n",
    "#     print(\"y : {}\".format(y))\n",
    "    # Optimize the model\n",
    "    loss_value, grads = grad(model, x, y)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables),\n",
    "                              global_step)\n",
    "\n",
    "    # Track progress\n",
    "    epoch_loss_avg(loss_value)  # add current batch loss\n",
    "    # compare predicted label to actual label\n",
    "    probabilities = model(x)\n",
    "#     print(\"predictions : {}\".format(probabilities))\n",
    "    predictions = tf.argmax(probabilities, axis=1, output_type=tf.int32)\n",
    "    \n",
    "    predictions = tf.reshape(predictions, [32,1])\n",
    "    \n",
    "    epoch_accuracy(predictions,y)\n",
    "\n",
    "  # end epoch\n",
    "  train_loss_results.append(epoch_loss_avg.result())\n",
    "  train_accuracy_results.append(epoch_accuracy.result())\n",
    "\n",
    "  if epoch % 2 == 0:\n",
    "    print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.8%}\".format(epoch,\n",
    "                                                                epoch_loss_avg.result(),\n",
    "                                                                epoch_accuracy.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Testing Data\n",
    "test_data = pd.read_csv(\"test_values.csv\")\n",
    "X_test = test_data.drop(columns=['building_id'])\n",
    "\n",
    "#One Hot Encoding Testing Data\n",
    "categorical_cols = ['land_surface_condition','foundation_type','roof_type','ground_floor_type','other_floor_type','position','plan_configuration','legal_ownership_status'];\n",
    "\n",
    "for col in categorical_cols:\n",
    "    X_test[col] = pd.Categorical(X_test[col])\n",
    "    X_test[col] = pd.Categorical(X_test[col])\n",
    "    \n",
    "dummies = pd.get_dummies(X_test['land_surface_condition'], prefix = 'land_surface_condition')\n",
    "for i in range (1,len(categorical_cols)):\n",
    "    dummies = pd.concat([dummies, pd.get_dummies(X_test[categorical_cols[i]], prefix = categorical_cols[i])],axis=1)\n",
    "    \n",
    "#Feature Scaling Testing Data\n",
    "X_test = X_test.drop(columns=categorical_cols)\n",
    "X_test = pd.DataFrame(scaler.fit_transform(X_test), columns=X_test.columns)\n",
    "print(X_test.shape)\n",
    "\n",
    "\n",
    "#Add categorical columns after feature scaling\n",
    "X_test = pd.concat([X_test, dummies],axis=1)\n",
    "\n",
    "# Prepare Data To Be Inserted Into Tensorflow Model\n",
    "X_testing_test = X_test.sample(1024)\n",
    "Y_testing_test = Y_test.sample(1024)\n",
    "\n",
    "Y_testing_test-=1\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((tf.cast(X_testing_test.values, tf.float32),\n",
    "            tf.cast(Y_testing_test.values, tf.int32)))\n",
    "test_dataset = test_dataset.shuffle(1000).repeat(10).batch(32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
